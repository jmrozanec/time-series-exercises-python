{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af433bf2-12c0-4508-afb2-057b1e4da3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the lib\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dc95a-7021-4557-b9b8-e6538ba8c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY='../data/forecasting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221848a-1ef1-4e94-ab5d-e6a77ced0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a527e6",
   "metadata": {},
   "source": [
    "# 1. Introduction to Time Series and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618e7d1",
   "metadata": {},
   "source": [
    "## 1.2. Machine learning and time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the New York stock exchange prices \n",
    "prices = pd.read_csv('{}/prices.csv'.format(DATA_DIRECTORY), index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161df74-1c72-46b3-b1d2-e9ebb5f43db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ace2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and show the time series on axis ax1\n",
    "fig, ax1 = plt.subplots()\n",
    "prices['close'].plot(ax=ax1, figsize=(12,10))\n",
    "plt.title('New York stock prices change')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde630ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the type of the data\n",
    "prices.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a3b0d-1c1e-4072-b0cf-afb97ce93faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.index = pd.to_datetime(prices.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01a8d8",
   "metadata": {},
   "source": [
    "# 2. Time Series Forecasting with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66744b15",
   "metadata": {},
   "source": [
    "If you want to predict patterns from data over time, there are special considerations to take in how you choose and construct your model. This section covers how to gain insights into the data before fitting your model, as well as best practices in using predictive modeling for time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59813b9f",
   "metadata": {},
   "source": [
    "## 2.1. Predicting data over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b98d156",
   "metadata": {},
   "source": [
    "We will deal with stock market prices that fluctuate over time. In this section we 've got historical prices from two tech companies (Ebay and Yahoo) in the DataFrame prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6360556-147c-4874-9a7b-692cf8809d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "preprocessed_prices = pd.read_csv('{}/preprocessed_prices.csv'.format(DATA_DIRECTORY), parse_dates=True, index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_prices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080fd9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the raw values over time\n",
    "preprocessed_prices.plot(y=['YHOO','EBAY'])\n",
    "plt.title('Market stock change for Yahoo and Ebay')\n",
    "plt.ylabel('Stock price')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d69e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot with one company per axis\n",
    "preprocessed_prices.plot.scatter('EBAY', 'YHOO')\n",
    "plt.title('Scatter plot of Yahoo and Ebay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45908ae0",
   "metadata": {},
   "source": [
    "Finally, encode time as the color of each datapoint in order to visualize how the relationship between these two variables changes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot with color relating to time\n",
    "preprocessed_prices.plot.scatter('EBAY', 'YHOO', c=preprocessed_prices.index, \n",
    "                    cmap=plt.cm.viridis, colorbar=True, figsize=(10,8))\n",
    "\n",
    "plt.title('Time color coded scatter plot of Yahoo and ebay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399395f",
   "metadata": {},
   "source": [
    "Now we will fit a linear regression, we will use the eBay, Nvidia and Yahoo stock prices as the features and the target value will be Apple stock price. We will use the linear regression model for predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf65390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting a simple regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use stock symbols to extract training data\n",
    "X = preprocessed_prices[['EBAY', 'NVDA', 'YHOO']]\n",
    "y = preprocessed_prices[['AAPL']]\n",
    "# Fit and score the model with cross-validation\n",
    "scores = cross_val_score(Ridge(), X, y, cv=3, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2763b6b-7ee2-4a75-87ca-999b9000d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get three R2 scores - one for each run of the crossvalidation.\n",
    "# For further details on the R2 score, please check: https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "np.round(scores, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179748ac-7d66-47b9-9da5-f648e8faf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing predicted values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, shuffle=False, random_state=1)\n",
    "\n",
    "# Fit the model and generate predictions\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "score = r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5d8f0-3c9e-4cfd-b031-2c931c6ee2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score: {}\".format(round(score, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644879d-c7b2-4789-bb18-ce55eb0d0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['predictions'] = predictions\n",
    "y_test.rename(columns= {'AAPL':'True_vlaue'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions along with the \"true\" values, and print the score\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(y_test['True_vlaue'], color='k', lw=3)\n",
    "ax.plot(y_test['predictions'], color='r', lw=2)\n",
    "ax.legend(['True values', 'Predicitions'])\n",
    "plt.title('Apple stock price true value and predicted price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd4891",
   "metadata": {},
   "source": [
    "Now you have an explanation for your poor score. The predictions clearly deviate from the true time series values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d251c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "alphas = [.1, 1e2, 1e3]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(y_test['True_vlaue'], color='k', alpha=.3, lw=3)\n",
    "color = ['r','b','g']\n",
    "for ii, alpha in enumerate(alphas):\n",
    "    y_test['predictions'] = Ridge(alpha=alpha).fit(X_train, y_train).predict(X_test)\n",
    "    ax.plot(y_test['predictions'],color[ii])\n",
    "ax.legend(['True values', 'Model 1', 'Model 2', 'Model 3'])\n",
    "ax.set(xlabel=\"Time\")\n",
    "ax.set(ylabel=\"stock price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91c0fe",
   "metadata": {},
   "source": [
    "## 2.2. Advanced time series forecatsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256570a1",
   "metadata": {},
   "source": [
    "We will use AIG company data, first we will drop some of the rows to act as missed data and then deal with it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing rows at random \n",
    "def remove_n_consecutive_rows(frame, n, percent):\n",
    "    chunks_to_remove = int(percent/100*frame.shape[0]/n)\n",
    "    #split the indices into chunks of length n+2\n",
    "    chunks = [list(range(i,i+n+2)) for i in range(0, frame.shape[0]-n)]\n",
    "    drop_indices = list()\n",
    "    for i in range(chunks_to_remove):\n",
    "        indices = random.choice(chunks)\n",
    "        drop_indices+=indices[1:-1]\n",
    "        #remove all chunks which contain overlapping values with indices\n",
    "        chunks = [c for c in chunks if not any(n in indices for n in c)]\n",
    "    #drop_indices = frame.index[drop_indices]    \n",
    "    frame.iloc[drop_indices,] = np.nan\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the AIG data without missing values \n",
    "AIG = pd.DataFrame(preprocessed_prices['AIG'])\n",
    "AIG.plot(figsize=(8,8))\n",
    "\n",
    "plt.title('The stock prices of the AIG company')\n",
    "plt.xlabel('Time (Years)')\n",
    "plt.ylabel('Stock price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the missing data\n",
    "AIG_missing_data = remove_n_consecutive_rows(AIG, 100, 20)\n",
    "\n",
    "AIG_missing_data.plot(figsize=(8,8))\n",
    "plt.title('The stock prices of the AIG company with missing data')\n",
    "plt.xlabel('Time (Years)')\n",
    "plt.ylabel('Stock price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125efa5",
   "metadata": {},
   "source": [
    "Lets now interpolate the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5f48f-a455-4fa1-97ed-25ff4671c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation in Pandas\n",
    "\n",
    "# Return a boolean that notes where missing values are\n",
    "missing_index = AIG_missing_data.isna()\n",
    "\n",
    "# Interpolate linearly within missing windows\n",
    "AIG_interp = AIG_missing_data.interpolate('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the interpolated data in red and the data w/ missing values in black\n",
    "ax = AIG_interp.plot(c='r')\n",
    "AIG_missing_data.plot(c='k',ax=ax, lw=2)\n",
    "ax.legend(['AIG_missing','AIG_interpolated'])\n",
    "ax.set(xlabel='Time (Years)')\n",
    "ax.set(ylabel='Stock value')\n",
    "ax.set(title='AIG stock price value with missing and interpolated values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming to percent change with Pandas\n",
    "\n",
    "def percent_change(values):\n",
    "    \"\"\"Calculates the % change between the last value\n",
    "    and the mean of previous values\"\"\"\n",
    "    # Separate the last value and all previous values into variables\n",
    "    previous_values = values[:-1]\n",
    "    last_value = values[-1]\n",
    "    # Calculate the % difference between the last value\n",
    "    # and the mean of earlier values\n",
    "    percent_change = (last_value - np.mean(previous_values)) \\\n",
    "    / np.mean(previous_values)\n",
    "    return percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfda679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformation to our data\n",
    "\n",
    "# Plot the raw data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# plot the AIG with interplotation\n",
    "axs[0].plot(AIG_interp, label='AIG')\n",
    "axs[0].legend()\n",
    "\n",
    "# Calculate % change and plot\n",
    "AIG_perc_change = AIG_interp.rolling(window=20).aggregate(percent_change)\n",
    "\n",
    "# plot the trasnfoemd AIG\n",
    "axs[1].plot(AIG_perc_change,label= 'AIG_transfomred')\n",
    "axs[1].legend()\n",
    "\n",
    "# set the title and x-axis and y-axis labels\n",
    "axs[0].set(xlabel='Time (Years)')\n",
    "axs[1].set(xlabel='Time (Years)')\n",
    "axs[0].set(ylabel='Stock market value')\n",
    "axs[1].set(ylabel='Percentage chnage in the stock market value')\n",
    "plt.suptitle('AIG stock prices vs percentage change in stock prices')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc7c58",
   "metadata": {},
   "source": [
    "#### Finding outliers\n",
    "Outliers are data points that are statistically different from the dataset as a whole. A common definition is any data point that is more than three standard deviations away from the mean of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a threshold on our data\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "legends = ['AIG','AIG_transfromed']\n",
    "for data, ax, l in zip([AIG_interp, AIG_perc_change], axs, legends):\n",
    "    # Calculate the mean / standard deviation for the data\n",
    "    data_mean = data.mean()\n",
    "    data_std = data.std()\n",
    "    # Plot the data, with a window that is 3 standard deviations\n",
    "    # around the mean\n",
    "    ax.plot(data, label=l)\n",
    "    ax.legend()\n",
    "    ax.axhline(data_mean[0] + data_std[0] * 3, ls='--', c='r')\n",
    "    ax.axhline(data_mean[0] - data_std[0] * 3, ls='--', c='r')\n",
    "\n",
    "# set the title and x-axis and y-axis labels\n",
    "axs[0].set(xlabel='Time (Years)')\n",
    "axs[1].set(xlabel='Time (Years)')\n",
    "axs[0].set(ylabel='Stock market value')\n",
    "axs[1].set(ylabel='Percentage chnage in the stock market value')\n",
    "plt.suptitle('AIG stock prices vs percentage change in stock prices with applied threshold')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6569b0c3",
   "metadata": {},
   "source": [
    "Lets replace the outliers using the threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the data so the mean is 0\n",
    "AIGِ_outlier_centered = AIG_perc_change - AIG_perc_change.mean()\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std = AIG_perc_change.std()\n",
    "\n",
    "# Use the absolute value of each data point\n",
    "# to make it easier to find outliers\n",
    "outliers = np.abs(AIGِ_outlier_centered) > (std * 3)\n",
    "\n",
    "# Replace outliers with the median value\n",
    "# Use np.nanmean since there may be nans around the outliers\n",
    "AIG_outlier_fixed = AIGِ_outlier_centered.copy()\n",
    "AIG_outlier_fixed[outliers] = np.nanmedian(AIG_outlier_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2,sharey=True,figsize=(20, 10))\n",
    "axs[0].plot(AIGِ_outlier_centered, label='AIG with outliers')\n",
    "axs[1].plot(AIG_outlier_fixed, label='AIG without outliers')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "axs[0].set(xlabel='Time (Years)')\n",
    "axs[1].set(xlabel='Time (Years)')\n",
    "plt.suptitle('AIG stock prices with outliers Vs AIG stock prices without outliers ')\n",
    "axs[0].set(ylabel='Percentage chnage in the stock market value')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12695d32",
   "metadata": {},
   "source": [
    "## 3.3. Creating features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using .aggregate for feature extraction\n",
    "# Visualize the raw data\n",
    "preprocessed_prices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ebc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a rolling window, then extract two features\n",
    "feats = preprocessed_prices.rolling(20).aggregate([np.std, np.max]).dropna()\n",
    "feats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ce5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats['AAPL'].plot(figsize=(10, 10))\n",
    "plt.xlabel('Date [Years] ')\n",
    "plt.ylabel('Stock price')\n",
    "plt.title('The std Vs max of the stock price change of Apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d722a89",
   "metadata": {},
   "source": [
    "#### Using partial() in Python\n",
    "A useful tool when using the dot-aggregate method is the partial function. This is built-in to Python, and lets you create a *new* function from an old one, with some of the parameters pre-configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we just take the mean, it returns a single value\n",
    "a = np.array([[0, 1, 2], [0, 1, 2], [0, 1, 2]])\n",
    "print(\"Mean: {}\".format(np.mean(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5445a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the partial function to initialize np.mean\n",
    "# with an axis parameter\n",
    "from functools import partial\n",
    "mean_over_first_axis = partial(np.mean, axis=0)\n",
    "print(\"Mean over axis: {}\".format(mean_over_first_axis(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ee20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles summarize your data\n",
    "print(\"Percentile q20: {}\".format(np.percentile(np.linspace(0, 200), q=20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining np.percentile() with partial functions to calculate a range of percentiles and apply it on toy data\n",
    "data = np.linspace(0, 100)\n",
    "# Create a list of functions using a list comprehension\n",
    "percentile_funcs = [partial(np.percentile, q=ii) for ii in [20, 40, 60]]\n",
    "# Calculate the output of each function in the same way\n",
    "percentiles = [i_func(data) for i_func in percentile_funcs]\n",
    "print(\"Percentiles 20, 40, and 60: {}\".format(percentiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d64c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multiple percentiles of a rolling window on our prices time series\n",
    "preprocessed_prices.rolling(20).aggregate(percentile_funcs).dropna().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005add1-c16f-4bd4-9473-911fe3d3489a",
   "metadata": {},
   "source": [
    "#### Date and time features using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e31f4-70e8-4a80-bb07-cc6e2e6903c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure our index is datetime\n",
    "preprocessed_prices.index = pd.to_datetime(preprocessed_prices.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0205403-9033-4826-b533-b5fc5fe3cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetime features\n",
    "day_of_week_num = preprocessed_prices.index.weekday\n",
    "print('Days of the week in numbers:', day_of_week_num[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcdb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week = preprocessed_prices.index.day_name()\n",
    "print('Days of the week in names:', day_of_week[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77415a09",
   "metadata": {},
   "source": [
    "# 3. Evaluation and Inspecting Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06987e",
   "metadata": {},
   "source": [
    "## 3.1. Creating features from the past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfad760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shifts in the data\n",
    "\n",
    "# slice the AIG company data\n",
    "rough_signal = preprocessed_prices['AIG']\n",
    "\n",
    "# Shifts \n",
    "shifts = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Create a dictionary of time-shifted data\n",
    "many_shifts = {'lag_{}'.format(ii): rough_signal.shift(ii) for ii in shifts}\n",
    "\n",
    "# Convert the shifts into a data frame\n",
    "many_shifts = pd.DataFrame(many_shifts)\n",
    "many_shifts.fillna(0, inplace=True)\n",
    "many_shifts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fffcd88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model using these input features\n",
    "model = Ridge()\n",
    "model.fit(many_shifts, rough_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de83437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8707c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit model coefficients\n",
    "fig, axs = plt.subplots(1, 2,figsize=(20, 10))\n",
    "\n",
    "axs[0].plot(many_shifts)\n",
    "\n",
    "\n",
    "axs[1].bar(many_shifts.columns, model.coef_)\n",
    "axs[1].set(xlabel='Coefficient name', ylabel='Coefficient value')\n",
    "\n",
    "\n",
    "# Set formatting so it looks nice\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.title('Model coefficients for each lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_prices.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fbba9",
   "metadata": {},
   "source": [
    "# Applying to a smooth signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shifts in the data\n",
    "\n",
    "# slice the AIG company data\n",
    "smooth_signal = preprocessed_prices['INTC']\n",
    "\n",
    "# Shifts \n",
    "shifts = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Create a dictionary of time-shifted data\n",
    "many_shifts = {'lag_{}'.format(ii): smooth_signal.shift(ii) for ii in shifts}\n",
    "\n",
    "# Convert the shifts into a data frame\n",
    "many_shifts = pd.DataFrame(many_shifts)\n",
    "many_shifts.fillna(0, inplace=True)\n",
    "many_shifts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfd9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "many_shifts.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30d804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model using these input features\n",
    "model = Ridge()\n",
    "model.fit(many_shifts, smooth_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eda63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit model coefficients\n",
    "fig, axs = plt.subplots(1, 2,figsize=(20, 10))\n",
    "\n",
    "axs[0].plot(many_shifts)\n",
    "\n",
    "axs[1].bar(many_shifts.columns, model.coef_)\n",
    "axs[1].set(xlabel='Coefficient name', ylabel='Coefficient value')\n",
    "\n",
    "# Set formatting so it looks nice\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.title('Model coefficients for each lag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3531c1f",
   "metadata": {},
   "source": [
    "## 3.2. Cross-validating time-series data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577da8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(results):\n",
    "    i = 0\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for result in results:\n",
    "        plt.plot(result[2],result[0],'o', label='iteration'+str(i))\n",
    "        plt.legend()\n",
    "        plt.xlabel('time')\n",
    "        plt.title('predicition order by time')\n",
    "        i = i+1\n",
    "    \n",
    "    i = 1\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for result in results:\n",
    "        plt.plot(np.arange((i-1)*len(result[0]),(i)*len(result[0])), result[0], 'o')\n",
    "        plt.xlabel('time')\n",
    "        plt.title('Prediction order by test prediction number')\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ShuffleSplit and create the cross-validation object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, random_state=1)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for rows_train, rows_test in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X.iloc[rows_train], y.iloc[rows_train])\n",
    "\n",
    "    # Generate predictions on the test data, score the predictions and collect\n",
    "    prediction = model.predict(X.iloc[rows_test])\n",
    "    score = r2_score(y.iloc[rows_test], prediction)\n",
    "    results.append((prediction, score, rows_test))\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(results):\n",
    "    i = 0\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for result in results:\n",
    "        plt.plot(result[1],result[0],'o', label='iteration'+str(i))\n",
    "        plt.legend()\n",
    "        plt.xlabel('time')\n",
    "        plt.title('predicition order by time')\n",
    "        i = i+1\n",
    "    \n",
    "    i = 1\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for result in results:\n",
    "        plt.plot(np.arange((i-1)*len(result[0]),(i)*len(result[0])), result[0], 'o')\n",
    "        plt.xlabel('time')\n",
    "        plt.title('Prediction order by test prediction number')\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold cross-validation object\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for rows_train, rows_test in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X.iloc[rows_train],y.iloc[rows_train])\n",
    "    \n",
    "    # Generate predictions on the test data and collect\n",
    "    prediction = model.predict(X.iloc[rows_test])\n",
    "    results.append((prediction, rows_test))\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create a time-series cross-validation object\n",
    "cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Iterate through CV splits\n",
    "fig, ax = plt.subplots()\n",
    "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
    "    # Plot the training data on each iteration to see the behavior of the CV\n",
    "    ax.plot(tr, ii + y.iloc[tr]/1000)\n",
    "    \n",
    "ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
    "ax.set(xlabel='time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f2e82",
   "metadata": {},
   "source": [
    "## 3.3. Stationarity and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eae224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold cross-validation object\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=10, shuffle=False)\n",
    "cv_coefficeints = []\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "\n",
    "for rows_train, rows_test in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X.iloc[rows_train],y.iloc[rows_train])\n",
    "    \n",
    "    # Generate predictions on the test data and collect\n",
    "    prediction = model.predict(X.iloc[rows_test])\n",
    "    results.append((prediction, rows_test))\n",
    "    cv_coefficeints.append(model.coef_)\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(cv_coefficeints)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f20195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping the mean\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# cv_coefficients has shape (n_cv_folds, n_coefficients)\n",
    "n_coefficients = np.shape(cv_coefficeints)[-1]\n",
    "n_boots = 100\n",
    "bootstrap_means = np.zeros((n_boots, n_coefficients))\n",
    "                           \n",
    "for ii in range(n_boots):\n",
    "    # Generate random indices for our data with replacement,\n",
    "    # then take the sample mean\n",
    "    random_sample = resample(cv_coefficeints)\n",
    "    bootstrap_means[ii] = np.mean(random_sample,axis=0)\n",
    "    \n",
    "# Compute the percentiles of choice for the bootstrapped means\n",
    "percentiles = np.percentile(bootstrap_means, (2.5, 97.5), axis=0)\n",
    "\n",
    "# Plotting the bootstrapped coefficients\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(X_df.columns, percentiles[0], marker='_', s=200)\n",
    "ax.scatter(X_df.columns, percentiles[1], marker='_', s=200)\n",
    "ax.set(title='95% confidence intervals for model coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93699470",
   "metadata": {},
   "source": [
    "### Assessing model performance stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e243e-a5ee-4667-b5c4-bab7645fa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score function will be the correlation between the predicted and the true values\n",
    "def correlation_coefficient(est, X, y):\n",
    "    \"\"\"Return the correlation coefficient\n",
    "    between model predictions and a validation set.\"\"\"\n",
    "    score = np.corrcoef(np.hstack((y, est.predict(X))))[1, 0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance over time\n",
    "# define the cv split and the regression model \n",
    "cv = TimeSeriesSplit(n_splits=100)\n",
    "model = Ridge()\n",
    "first_indices = []\n",
    "\n",
    "# Grab the date of the first index of each test set\n",
    "for rows_train, rows_test in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    first_indices.append(X_df.index[rows_test[0]])\n",
    "    \n",
    "# Calculate the CV scores and convert to a Pandas Series\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring = correlation_coefficient)\n",
    "cv_scores = pd.DataFrame(cv_scores, index=first_indices)\n",
    "\n",
    "# Visualizing model scores as a timeseries\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 20), sharex=False)\n",
    "\n",
    "# Calculate a rolling mean of scores over time\n",
    "cv_scores_mean = cv_scores.rolling(10, min_periods=1).mean()\n",
    "cv_scores_mean.plot(ax=axs[0])\n",
    "axs[0].set(title='Validation scores (correlation)', ylim=[0, 1])\n",
    "\n",
    "# Plot the raw data\n",
    "X_df.plot(ax=axs[1])\n",
    "axs[1].set(title='Validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec577b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the last 100 data points in the training data\n",
    "window = 100\n",
    "\n",
    "# Initialize the CV with this window size\n",
    "cv = TimeSeriesSplit(n_splits=10, max_train_size=window)\n",
    "\n",
    "model = Ridge()\n",
    "first_indices = []\n",
    "\n",
    "for rows_train, rows_test in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    first_indices.append(X_df.index[rows_test[0]])\n",
    "    \n",
    "\n",
    "model = Ridge()   \n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring = correlation_coefficient)\n",
    "\n",
    "# Calculate the CV scores and convert them to a Pandas Series\n",
    "cv_scores = pd.DataFrame(cv_scores, index=first_indices)\n",
    "\n",
    "#Visualizing model scores as a time series\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 20), sharex=False)\n",
    "\n",
    "# Calculate a rolling mean of scores over time\n",
    "cv_scores_mean = cv_scores.rolling(10, min_periods=1).mean()\n",
    "cv_scores_mean.plot(ax=axs[0])\n",
    "axs[0].set(title='Test scores (correlation)', ylim=[0, 1])\n",
    "\n",
    "# Plot the raw data\n",
    "X_df.plot(ax=axs[1])\n",
    "axs[1].set(title='Test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c43ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
